{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = \"../remote/Silicon_etch.obj\"\n",
    "# file1 = \"../remote/Nitride_etch.obj\"\n",
    "file2 = \"../test/initial_struct_600_600.obj\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import cv2\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import os\n",
    "\n",
    "class OBJLoader:\n",
    "    \"\"\"Load and parse Wavefront .obj files\"\"\"\n",
    "    \n",
    "    def __init__(self, filepath):\n",
    "        self.vertices = []\n",
    "        self.faces = []\n",
    "        self.load_obj(filepath)\n",
    "    \n",
    "    def load_obj(self, filepath):\n",
    "        \"\"\"Parse .obj file and extract vertices and faces\"\"\"\n",
    "        with open(filepath, 'r') as file:\n",
    "            for line in file:\n",
    "                line = line.strip()\n",
    "                if line.startswith('v '):  # Vertex\n",
    "                    parts = line.split()\n",
    "                    vertex = [float(parts[1]), float(parts[2]), float(parts[3])]\n",
    "                    self.vertices.append(vertex)\n",
    "                elif line.startswith('f '):  # Face\n",
    "                    parts = line.split()\n",
    "                    # Handle different face formats (v, v/vt, v/vt/vn)\n",
    "                    face = []\n",
    "                    for part in parts[1:]:\n",
    "                        vertex_idx = int(part.split('/')[0]) - 1  # OBJ uses 1-based indexing\n",
    "                        face.append(vertex_idx)\n",
    "                    self.faces.append(face)\n",
    "        \n",
    "        self.vertices = np.array(self.vertices)\n",
    "        print(f\"Loaded {len(self.vertices)} vertices and {len(self.faces)} faces from {filepath}\")\n",
    "\n",
    "class CrossSectionAnalyzer:\n",
    "    \"\"\"Analyze cross-sections of 3D models and compare using SIFT+FLANN\"\"\"\n",
    "    \n",
    "    def __init__(self, obj1_path, obj2_path):\n",
    "        self.model1 = OBJLoader(obj1_path)\n",
    "        self.model2 = OBJLoader(obj2_path)\n",
    "        self.sift = cv2.SIFT_create()\n",
    "        \n",
    "        # FLANN parameters\n",
    "        FLANN_INDEX_KDTREE = 0\n",
    "        index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
    "        search_params = dict(checks=100)\n",
    "        self.flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "    \n",
    "    def get_cross_section_points(self, model, y_slice):\n",
    "        \"\"\"Extract cross-section points at a given Y coordinate\"\"\"\n",
    "        vertices = model.vertices\n",
    "        faces = model.faces\n",
    "        \n",
    "        cross_section_points = []\n",
    "        \n",
    "        # Find edges that intersect the Y plane\n",
    "        for face in faces:\n",
    "            if len(face) < 3:\n",
    "                continue\n",
    "                \n",
    "            # Check each edge of the face\n",
    "            for i in range(len(face)):\n",
    "                v1_idx = face[i]\n",
    "                v2_idx = face[(i + 1) % len(face)]\n",
    "                \n",
    "                if v1_idx >= len(vertices) or v2_idx >= len(vertices):\n",
    "                    continue\n",
    "                \n",
    "                v1 = vertices[v1_idx]\n",
    "                v2 = vertices[v2_idx]\n",
    "                \n",
    "                # Check if edge crosses the Y plane\n",
    "                if (v1[1] <= y_slice <= v2[1]) or (v2[1] <= y_slice <= v1[1]):\n",
    "                    if abs(v1[1] - v2[1]) > 1e-6:  # Avoid division by zero\n",
    "                        # Linear interpolation to find intersection point\n",
    "                        t = (y_slice - v1[1]) / (v2[1] - v1[1])\n",
    "                        x = v1[0] + t * (v2[0] - v1[0])\n",
    "                        z = v1[2] + t * (v2[2] - v1[2])\n",
    "                        cross_section_points.append([x, z])\n",
    "        \n",
    "        return np.array(cross_section_points)\n",
    "    \n",
    "    def points_to_image(self, points, image_size=512, margin=0.1):\n",
    "        \"\"\"Convert 2D points to binary image\"\"\"\n",
    "        if len(points) == 0:\n",
    "            return np.zeros((image_size, image_size), dtype=np.uint8)\n",
    "        \n",
    "        # Find bounding box\n",
    "        min_x, max_x = points[:, 0].min(), points[:, 0].max()\n",
    "        min_z, max_z = points[:, 1].min(), points[:, 1].max()\n",
    "        \n",
    "        # Add margin\n",
    "        range_x = max_x - min_x\n",
    "        range_z = max_z - min_z\n",
    "        max_range = max(range_x, range_z)\n",
    "        \n",
    "        if max_range == 0:\n",
    "            return np.zeros((image_size, image_size), dtype=np.uint8)\n",
    "        \n",
    "        margin_size = max_range * margin\n",
    "        \n",
    "        # Create image\n",
    "        image = np.zeros((image_size, image_size), dtype=np.uint8)\n",
    "        \n",
    "        # Map points to image coordinates\n",
    "        for point in points:\n",
    "            x = int((point[0] - min_x + margin_size) / (max_range + 2 * margin_size) * (image_size - 1))\n",
    "            z = int((point[1] - min_z + margin_size) / (max_range + 2 * margin_size) * (image_size - 1))\n",
    "            \n",
    "            if 0 <= x < image_size and 0 <= z < image_size:\n",
    "                # Draw a small circle around each point\n",
    "                cv2.circle(image, (x, z), 2, 255, -1)\n",
    "        \n",
    "        return image\n",
    "    \n",
    "    def extract_sift_features(self, image):\n",
    "        \"\"\"Extract SIFT features from image\"\"\"\n",
    "        keypoints, descriptors = self.sift.detectAndCompute(image, None)\n",
    "        return keypoints, descriptors\n",
    "    \n",
    "    def match_features(self, desc1, desc2):\n",
    "        \"\"\"Match features using FLANN matcher\"\"\"\n",
    "        if desc1 is None or desc2 is None or len(desc1) < 2 or len(desc2) < 2:\n",
    "            return [], 0.0\n",
    "        \n",
    "        # Find matches\n",
    "        matches = self.flann.knnMatch(desc1, desc2, k=2)\n",
    "        \n",
    "        # Apply Lowe's ratio test\n",
    "        good_matches = []\n",
    "        for match_pair in matches:\n",
    "            if len(match_pair) == 2:\n",
    "                m, n = match_pair\n",
    "                if m.distance < 0.7 * n.distance:\n",
    "                    good_matches.append(m)\n",
    "        \n",
    "        # Calculate similarity score\n",
    "        if len(good_matches) == 0:\n",
    "            similarity = 0.0\n",
    "        else:\n",
    "            # Normalize by the number of features in both images\n",
    "            similarity = len(good_matches) / max(len(desc1), len(desc2))\n",
    "        \n",
    "        return good_matches, similarity\n",
    "    \n",
    "    def analyze_cross_sections(self, num_slices=10, visualization=True):\n",
    "        \"\"\"Analyze cross-sections and compare models\"\"\"\n",
    "        # Get Y bounds for both models\n",
    "        y_min = min(self.model1.vertices[:, 1].min(), self.model2.vertices[:, 1].min())\n",
    "        y_max = max(self.model1.vertices[:, 1].max(), self.model2.vertices[:, 1].max())\n",
    "        \n",
    "        y_slices = np.linspace(y_min, y_max, num_slices)\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        if visualization:\n",
    "            fig, axes = plt.subplots(3, num_slices, figsize=(40, 24))\n",
    "            fig.suptitle('Cross-Section Comparison: Model 1 vs Model 2', fontsize=16)\n",
    "        \n",
    "        for i, y_slice in enumerate(y_slices):\n",
    "            # Get cross-section points\n",
    "            points1 = self.get_cross_section_points(self.model1, y_slice)\n",
    "            points2 = self.get_cross_section_points(self.model2, y_slice)\n",
    "            \n",
    "            # Convert to images\n",
    "            img1 = self.points_to_image(points1)\n",
    "            img2 = self.points_to_image(points2)\n",
    "            \n",
    "            # Extract SIFT features\n",
    "            kp1, desc1 = self.extract_sift_features(img1)\n",
    "            kp2, desc2 = self.extract_sift_features(img2)\n",
    "            \n",
    "            # Match features\n",
    "            matches, similarity = self.match_features(desc1, desc2)\n",
    "            \n",
    "            results.append({\n",
    "                'y_slice': y_slice,\n",
    "                'points1': len(points1),\n",
    "                'points2': len(points2),\n",
    "                'features1': len(kp1) if kp1 else 0,\n",
    "                'features2': len(kp2) if kp2 else 0,\n",
    "                'matches': len(matches),\n",
    "                'similarity': similarity\n",
    "            })\n",
    "            \n",
    "            if visualization:\n",
    "                # Plot Model 1 cross-section\n",
    "                axes[2, i].imshow(img1, cmap='gray')\n",
    "                axes[2, i].set_title(f'Model 1\\nY={y_slice:.2f}')\n",
    "                axes[2, i].axis('off')\n",
    "                \n",
    "                # Plot Model 2 cross-section\n",
    "                axes[1, i].imshow(img2, cmap='gray')\n",
    "                axes[1, i].set_title(f'Model 2\\nY={y_slice:.2f}')\n",
    "                axes[1, i].axis('off')\n",
    "                \n",
    "                # Plot matches visualization\n",
    "                if len(matches) > 0 and desc1 is not None and desc2 is not None:\n",
    "                    # Create match visualization\n",
    "                    match_img = cv2.drawMatches(img1, kp1, img2, kp2, matches[:10], None, \n",
    "                                              flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "                    axes[0, i].imshow(match_img, cmap='gray')\n",
    "                else:\n",
    "                    # Show both images side by side\n",
    "                    combined = np.hstack([img1, img2])\n",
    "                    axes[0, i].imshow(combined, cmap='gray')\n",
    "                \n",
    "                axes[0, i].set_title(f'Matches: {len(matches)}\\nSim: {similarity:.3f}')\n",
    "                axes[0, i].axis('off')\n",
    "        \n",
    "        if visualization:\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def plot_similarity_analysis(self, results):\n",
    "        \"\"\"Plot similarity analysis results\"\"\"\n",
    "        y_slices = [r['y_slice'] for r in results]\n",
    "        similarities = [r['similarity'] for r in results]\n",
    "        matches = [r['matches'] for r in results]\n",
    "        \n",
    "        fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))\n",
    "        \n",
    "        # Similarity over Y slices\n",
    "        ax1.plot(y_slices, similarities, 'b-o', linewidth=2, markersize=6)\n",
    "        ax1.set_xlabel('Y Coordinate')\n",
    "        ax1.set_ylabel('Similarity Score')\n",
    "        ax1.set_title('Similarity Score vs Y-Slice')\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Number of matches\n",
    "        ax2.bar(range(len(matches)), matches, alpha=0.7, color='green')\n",
    "        ax2.set_xlabel('Slice Index')\n",
    "        ax2.set_ylabel('Number of Matches')\n",
    "        ax2.set_title('Feature Matches per Slice')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Overall statistics\n",
    "        avg_similarity = np.mean(similarities)\n",
    "        max_similarity = np.max(similarities)\n",
    "        total_matches = np.sum(matches)\n",
    "        \n",
    "        stats_text = f'Average Similarity: {avg_similarity:.3f}\\n'\n",
    "        stats_text += f'Maximum Similarity: {max_similarity:.3f}\\n'\n",
    "        stats_text += f'Total Matches: {total_matches}\\n'\n",
    "        stats_text += f'Slices Analyzed: {len(results)}'\n",
    "        \n",
    "        ax3.text(0.1, 0.7, stats_text, transform=ax3.transAxes, fontsize=12,\n",
    "                bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightblue\", alpha=0.7))\n",
    "        ax3.set_title('Overall Statistics')\n",
    "        ax3.axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return {\n",
    "            'average_similarity': avg_similarity,\n",
    "            'max_similarity': max_similarity,\n",
    "            'total_matches': total_matches\n",
    "        }\n",
    "\n",
    "# Example usage\n",
    "def main():\n",
    "    \"\"\"Main function to demonstrate the cross-section comparison\"\"\"\n",
    "    # Replace these paths with your actual .obj file paths\n",
    "    obj1_path = file1  # Path to first .obj file\n",
    "    obj2_path = file2  # Path to second .obj file\n",
    "    \n",
    "    # Check if files exist\n",
    "    if not os.path.exists(obj1_path) or not os.path.exists(obj2_path):\n",
    "        print(\"Error: Please provide valid paths to .obj files\")\n",
    "        print(\"Update the obj1_path and obj2_path variables with your file paths\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        # Create analyzer\n",
    "        analyzer = CrossSectionAnalyzer(obj1_path, obj2_path)\n",
    "        \n",
    "        # Analyze cross-sections\n",
    "        print(\"Analyzing cross-sections...\")\n",
    "        results = analyzer.analyze_cross_sections(num_slices=4, visualization=True)\n",
    "        \n",
    "        # Plot similarity analysis\n",
    "        print(\"Generating similarity analysis...\")\n",
    "        stats = analyzer.plot_similarity_analysis(results)\n",
    "        \n",
    "        # Print detailed results\n",
    "        print(\"\\nDetailed Results:\")\n",
    "        print(\"-\" * 60)\n",
    "        for i, result in enumerate(results):\n",
    "            print(f\"Slice {i+1} (Y={result['y_slice']:.2f}):\")\n",
    "            print(f\"  Points: {result['points1']} vs {result['points2']}\")\n",
    "            print(f\"  Features: {result['features1']} vs {result['features2']}\")\n",
    "            print(f\"  Matches: {result['matches']}\")\n",
    "            print(f\"  Similarity: {result['similarity']:.3f}\")\n",
    "            print()\n",
    "        \n",
    "        print(f\"Overall Similarity Score: {stats['average_similarity']:.3f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during analysis: {str(e)}\")\n",
    "        print(\"Please check your .obj file paths and formats\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import cv2\n",
    "from sklearn.metrics import jaccard_score\n",
    "from scipy import ndimage\n",
    "from scipy.spatial.distance import directed_hausdorff\n",
    "import os\n",
    "\n",
    "class OBJLoader:\n",
    "    \"\"\"Class to load and parse Wavefront .obj files\"\"\"\n",
    "    \n",
    "    def __init__(self, filepath):\n",
    "        self.vertices = []\n",
    "        self.faces = []\n",
    "        self.load_obj(filepath)\n",
    "    \n",
    "    def load_obj(self, filepath):\n",
    "        \"\"\"Load vertices and faces from .obj file\"\"\"\n",
    "        with open(filepath, 'r') as file:\n",
    "            for line in file:\n",
    "                line = line.strip()\n",
    "                if line.startswith('v '):  # Vertex\n",
    "                    parts = line.split()\n",
    "                    vertex = [float(parts[1]), float(parts[2]), float(parts[3])]\n",
    "                    self.vertices.append(vertex)\n",
    "                elif line.startswith('f '):  # Face\n",
    "                    parts = line.split()\n",
    "                    # Handle different face formats (with or without texture/normal indices)\n",
    "                    face = []\n",
    "                    for part in parts[1:]:\n",
    "                        vertex_idx = int(part.split('/')[0]) - 1  # .obj indices start from 1\n",
    "                        face.append(vertex_idx)\n",
    "                    self.faces.append(face)\n",
    "        \n",
    "        self.vertices = np.array(self.vertices)\n",
    "        print(f\"Loaded {len(self.vertices)} vertices and {len(self.faces)} faces\")\n",
    "\n",
    "class GeometryYSlicer:\n",
    "    \"\"\"Class to slice 3D geometry along Y-axis and extract contours\"\"\"\n",
    "    \n",
    "    def __init__(self, obj_loader, num_slices=20):\n",
    "        self.vertices = obj_loader.vertices\n",
    "        self.faces = obj_loader.faces\n",
    "        self.num_slices = num_slices\n",
    "        \n",
    "        # Check for valid vertices\n",
    "        if len(self.vertices) == 0:\n",
    "            raise ValueError(\"No vertices found in the model\")\n",
    "        \n",
    "        # Remove any rows with NaN or infinite values\n",
    "        valid_vertices = self.vertices[np.isfinite(self.vertices).all(axis=1)]\n",
    "        if len(valid_vertices) == 0:\n",
    "            raise ValueError(\"No valid vertices found (all contain NaN or infinite values)\")\n",
    "        \n",
    "        self.y_min = np.min(valid_vertices[:, 1])\n",
    "        self.y_max = np.max(valid_vertices[:, 1])\n",
    "        \n",
    "        if np.isnan(self.y_min) or np.isnan(self.y_max) or self.y_min == self.y_max:\n",
    "            raise ValueError(\"Invalid Y range in model vertices\")\n",
    "        \n",
    "    def get_slice_contours(self):\n",
    "        \"\"\"Extract contours at different Y levels\"\"\"\n",
    "        y_levels = np.linspace(self.y_min, self.y_max, self.num_slices)\n",
    "        contours = []\n",
    "        \n",
    "        for y_level in y_levels:\n",
    "            slice_points = self.slice_at_y(y_level)\n",
    "            if len(slice_points) > 0:\n",
    "                contour_image = self.points_to_image(slice_points)\n",
    "                contours.append({\n",
    "                    'y_level': y_level,\n",
    "                    'points': slice_points,\n",
    "                    'image': contour_image\n",
    "                })\n",
    "        \n",
    "        return contours\n",
    "    \n",
    "    def slice_at_y(self, y_level, tolerance=0.01):\n",
    "        \"\"\"Find intersection points with a plane at given Y level\"\"\"\n",
    "        intersection_points = []\n",
    "        \n",
    "        for face in self.faces:\n",
    "            if len(face) < 3:\n",
    "                continue\n",
    "                \n",
    "            # Check each edge of the face for intersection\n",
    "            for i in range(len(face)):\n",
    "                v1_idx = face[i]\n",
    "                v2_idx = face[(i + 1) % len(face)]\n",
    "                \n",
    "                if v1_idx >= len(self.vertices) or v2_idx >= len(self.vertices):\n",
    "                    continue\n",
    "                    \n",
    "                v1 = self.vertices[v1_idx]\n",
    "                v2 = self.vertices[v2_idx]\n",
    "                \n",
    "                # Check for NaN or infinite values in vertices\n",
    "                if not (np.isfinite(v1).all() and np.isfinite(v2).all()):\n",
    "                    continue\n",
    "                \n",
    "                # Check if edge crosses the Y plane\n",
    "                if (v1[1] <= y_level <= v2[1]) or (v2[1] <= y_level <= v1[1]):\n",
    "                    y_diff = abs(v1[1] - v2[1])\n",
    "                    if y_diff > tolerance:  # Avoid division by zero\n",
    "                        # Linear interpolation to find intersection point\n",
    "                        t = (y_level - v1[1]) / (v2[1] - v1[1])\n",
    "                        \n",
    "                        # Check if t is valid\n",
    "                        if np.isfinite(t):\n",
    "                            intersection_x = v1[0] + t * (v2[0] - v1[0])\n",
    "                            intersection_z = v1[2] + t * (v2[2] - v1[2])\n",
    "                            \n",
    "                            # Check if intersection point is valid\n",
    "                            if np.isfinite(intersection_x) and np.isfinite(intersection_z):\n",
    "                                intersection_points.append([intersection_x, intersection_z])\n",
    "        \n",
    "        return np.array(intersection_points) if intersection_points else np.array([])\n",
    "    \n",
    "    def points_to_image(self, points, image_size=256):\n",
    "        \"\"\"Convert slice points to binary image for contour analysis\"\"\"\n",
    "        if len(points) == 0:\n",
    "            return np.zeros((image_size, image_size), dtype=np.uint8)\n",
    "        \n",
    "        # Remove any NaN or infinite values\n",
    "        points = points[~np.isnan(points).any(axis=1)]\n",
    "        points = points[np.isfinite(points).all(axis=1)]\n",
    "        \n",
    "        if len(points) == 0:\n",
    "            return np.zeros((image_size, image_size), dtype=np.uint8)\n",
    "        \n",
    "        # Normalize points to image coordinates\n",
    "        x_min, x_max = np.min(points[:, 0]), np.max(points[:, 0])\n",
    "        z_min, z_max = np.min(points[:, 1]), np.max(points[:, 1])\n",
    "        \n",
    "        # Check for valid ranges\n",
    "        x_range = x_max - x_min\n",
    "        z_range = z_max - z_min\n",
    "        \n",
    "        if x_range == 0 or z_range == 0 or np.isnan(x_range) or np.isnan(z_range):\n",
    "            # Handle degenerate cases\n",
    "            image = np.zeros((image_size, image_size), dtype=np.uint8)\n",
    "            center = image_size // 2\n",
    "            image[center-2:center+3, center-2:center+3] = 255\n",
    "            return image\n",
    "        \n",
    "        # Add padding to avoid edge issues\n",
    "        padding = 0.1\n",
    "        x_min -= x_range * padding\n",
    "        x_max += x_range * padding\n",
    "        z_min -= z_range * padding\n",
    "        z_max += z_range * padding\n",
    "        \n",
    "        # Update ranges after padding\n",
    "        x_range = x_max - x_min\n",
    "        z_range = z_max - z_min\n",
    "        \n",
    "        # Create binary image\n",
    "        image = np.zeros((image_size, image_size), dtype=np.uint8)\n",
    "        \n",
    "        for point in points:\n",
    "            if not (np.isfinite(point[0]) and np.isfinite(point[1])):\n",
    "                continue\n",
    "                \n",
    "            x_norm_float = (point[0] - x_min) / x_range * (image_size - 1)\n",
    "            z_norm_float = (point[1] - z_min) / z_range * (image_size - 1)\n",
    "            \n",
    "            # Check for NaN before converting to int\n",
    "            if np.isnan(x_norm_float) or np.isnan(z_norm_float):\n",
    "                continue\n",
    "                \n",
    "            x_norm = int(np.clip(x_norm_float, 0, image_size - 1))\n",
    "            z_norm = int(np.clip(z_norm_float, 0, image_size - 1))\n",
    "            \n",
    "            image[z_norm, x_norm] = 255\n",
    "        \n",
    "        # Apply morphological operations to create cleaner contours\n",
    "        kernel = np.ones((3, 3), np.uint8)\n",
    "        image = cv2.dilate(image, kernel, iterations=1)\n",
    "        image = cv2.erode(image, kernel, iterations=1)\n",
    "        \n",
    "        return image\n",
    "\n",
    "class ContourComparator:\n",
    "    \"\"\"Class to compare contours using various similarity metrics\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def compare_contours(self, contours1, contours2):\n",
    "        \"\"\"Compare two sets of contours and return similarity metrics\"\"\"\n",
    "        min_length = min(len(contours1), len(contours2))\n",
    "        similarities = []\n",
    "        \n",
    "        for i in range(min_length):\n",
    "            img1 = contours1[i]['image']\n",
    "            img2 = contours2[i]['image']\n",
    "            \n",
    "            # Calculate multiple similarity metrics\n",
    "            similarity = {\n",
    "                'y_level': contours1[i]['y_level'],\n",
    "                'structural_similarity': self.structural_similarity(img1, img2),\n",
    "                'contour_matching': self.contour_feature_matching(img1, img2),\n",
    "                'jaccard_index': self.jaccard_similarity(img1, img2),\n",
    "                'hausdorff_distance': self.hausdorff_similarity(img1, img2)\n",
    "            }\n",
    "            similarities.append(similarity)\n",
    "        \n",
    "        return similarities\n",
    "    \n",
    "    def structural_similarity(self, img1, img2):\n",
    "        \"\"\"Calculate structural similarity using template matching\"\"\"\n",
    "        if img1.shape != img2.shape:\n",
    "            img2 = cv2.resize(img2, (img1.shape[1], img1.shape[0]))\n",
    "        \n",
    "        # Check if images are valid\n",
    "        if img1.size == 0 or img2.size == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        # Normalize images\n",
    "        img1_norm = img1.astype(np.float32) / 255.0\n",
    "        img2_norm = img2.astype(np.float32) / 255.0\n",
    "        \n",
    "        # Check for all-zero images\n",
    "        if np.sum(img1_norm) == 0 and np.sum(img2_norm) == 0:\n",
    "            return 1.0  # Both are empty\n",
    "        elif np.sum(img1_norm) == 0 or np.sum(img2_norm) == 0:\n",
    "            return 0.0  # One is empty\n",
    "        \n",
    "        # Calculate correlation coefficient\n",
    "        try:\n",
    "            correlation = cv2.matchTemplate(img1_norm, img2_norm, cv2.TM_CCOEFF_NORMED)\n",
    "            result = correlation[0, 0]\n",
    "            \n",
    "            # Check for NaN result\n",
    "            if np.isnan(result) or not np.isfinite(result):\n",
    "                return 0.0\n",
    "            \n",
    "            return max(0.0, min(1.0, result))  # Clamp to [0, 1]\n",
    "        except:\n",
    "            return 0.0\n",
    "    \n",
    "    def contour_feature_matching(self, img1, img2):\n",
    "        \"\"\"Use OpenCV feature matching for contour comparison\"\"\"\n",
    "        try:\n",
    "            # Find contours\n",
    "            contours1, _ = cv2.findContours(img1, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            contours2, _ = cv2.findContours(img2, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            \n",
    "            if len(contours1) == 0 or len(contours2) == 0:\n",
    "                return 0.0\n",
    "            \n",
    "            # Get the largest contour from each image\n",
    "            contour1 = max(contours1, key=cv2.contourArea)\n",
    "            contour2 = max(contours2, key=cv2.contourArea)\n",
    "            \n",
    "            # Check if contours are valid\n",
    "            if len(contour1) < 3 or len(contour2) < 3:\n",
    "                return 0.0\n",
    "            \n",
    "            # Use Hu moments for shape comparison\n",
    "            moments1 = cv2.moments(contour1)\n",
    "            moments2 = cv2.moments(contour2)\n",
    "            \n",
    "            # Check if moments are valid\n",
    "            if moments1['m00'] == 0 or moments2['m00'] == 0:\n",
    "                return 0.0\n",
    "            \n",
    "            hu1 = cv2.HuMoments(moments1).flatten()\n",
    "            hu2 = cv2.HuMoments(moments2).flatten()\n",
    "            \n",
    "            # Check for NaN or infinite values in Hu moments\n",
    "            if not (np.isfinite(hu1).all() and np.isfinite(hu2).all()):\n",
    "                return 0.0\n",
    "            \n",
    "            # Calculate similarity based on Hu moments\n",
    "            diff = np.sum(np.abs(hu1 - hu2))\n",
    "            if np.isnan(diff) or not np.isfinite(diff):\n",
    "                return 0.0\n",
    "            \n",
    "            similarity = 1.0 / (1.0 + diff)\n",
    "            return max(0.0, min(1.0, similarity))  # Clamp to [0, 1]\n",
    "            \n",
    "        except Exception as e:\n",
    "            return 0.0\n",
    "    \n",
    "    def jaccard_similarity(self, img1, img2):\n",
    "        \"\"\"Calculate Jaccard index (Intersection over Union)\"\"\"\n",
    "        if img1.shape != img2.shape:\n",
    "            img2 = cv2.resize(img2, (img1.shape[1], img1.shape[0]))\n",
    "        \n",
    "        # Convert to binary\n",
    "        binary1 = (img1 > 127).astype(int).flatten()\n",
    "        binary2 = (img2 > 127).astype(int).flatten()\n",
    "        \n",
    "        intersection = np.sum(binary1 & binary2)\n",
    "        union = np.sum(binary1 | binary2)\n",
    "        \n",
    "        if union == 0:\n",
    "            return 1.0  # Both images are empty\n",
    "        return intersection / union\n",
    "    \n",
    "    def hausdorff_similarity(self, img1, img2):\n",
    "        \"\"\"Calculate similarity based on Hausdorff distance\"\"\"\n",
    "        try:\n",
    "            # Find contour points\n",
    "            points1 = np.column_stack(np.where(img1 > 127))\n",
    "            points2 = np.column_stack(np.where(img2 > 127))\n",
    "            \n",
    "            if len(points1) == 0 or len(points2) == 0:\n",
    "                return 0.0\n",
    "            \n",
    "            # Remove any invalid points\n",
    "            points1 = points1[np.isfinite(points1).all(axis=1)]\n",
    "            points2 = points2[np.isfinite(points2).all(axis=1)]\n",
    "            \n",
    "            if len(points1) == 0 or len(points2) == 0:\n",
    "                return 0.0\n",
    "            \n",
    "            # Calculate Hausdorff distance\n",
    "            distance1 = directed_hausdorff(points1, points2)[0]\n",
    "            distance2 = directed_hausdorff(points2, points1)[0]\n",
    "            \n",
    "            if np.isnan(distance1) or np.isnan(distance2):\n",
    "                return 0.0\n",
    "            \n",
    "            distance = max(distance1, distance2)\n",
    "            \n",
    "            # Convert to similarity (inverse relationship)\n",
    "            if distance == 0:\n",
    "                return 1.0\n",
    "            \n",
    "            similarity = 1.0 / (1.0 + distance / 100.0)  # Normalize\n",
    "            return max(0.0, min(1.0, similarity))  # Clamp to [0, 1]\n",
    "            \n",
    "        except Exception as e:\n",
    "            return 0.0\n",
    "\n",
    "class Visualizer:\n",
    "    \"\"\"Class to visualize results\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def plot_3d_models(self, obj1, obj2):\n",
    "        \"\"\"Plot both 3D models for reference\"\"\"\n",
    "        fig = plt.figure(figsize=(15, 6))\n",
    "        \n",
    "        # Plot first model\n",
    "        ax1 = fig.add_subplot(121, projection='3d')\n",
    "        ax1.scatter(obj1.vertices[:, 0], obj1.vertices[:, 1], obj1.vertices[:, 2], \n",
    "                   c='blue', alpha=0.6, s=1)\n",
    "        ax1.set_title('Model 1')\n",
    "        ax1.set_xlabel('X')\n",
    "        ax1.set_ylabel('Y')\n",
    "        ax1.set_zlabel('Z')\n",
    "        \n",
    "        # Plot second model\n",
    "        ax2 = fig.add_subplot(122, projection='3d')\n",
    "        ax2.scatter(obj2.vertices[:, 0], obj2.vertices[:, 1], obj2.vertices[:, 2], \n",
    "                   c='red', alpha=0.6, s=1)\n",
    "        ax2.set_title('Model 2')\n",
    "        ax2.set_xlabel('X')\n",
    "        ax2.set_ylabel('Y')\n",
    "        ax2.set_zlabel('Z')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def plot_slice_comparison(self, contours1, contours2, similarities, num_display=6):\n",
    "        \"\"\"Plot slice contours and their comparisons\"\"\"\n",
    "        num_slices = min(len(contours1), len(contours2), num_display)\n",
    "        fig, axes = plt.subplots(3, num_slices, figsize=(3*num_slices, 9))\n",
    "        \n",
    "        for i in range(num_slices):\n",
    "            # Original contour 1\n",
    "            axes[0, i].imshow(contours1[i]['image'], cmap='Blues')\n",
    "            axes[0, i].set_title(f'Model 1\\nY={contours1[i][\"y_level\"]:.2f}')\n",
    "            axes[0, i].axis('off')\n",
    "            \n",
    "            # Original contour 2\n",
    "            axes[1, i].imshow(contours2[i]['image'], cmap='Reds')\n",
    "            axes[1, i].set_title(f'Model 2\\nY={contours2[i][\"y_level\"]:.2f}')\n",
    "            axes[1, i].axis('off')\n",
    "            \n",
    "            # Overlay comparison\n",
    "            overlay = np.zeros((*contours1[i]['image'].shape, 3))\n",
    "            overlay[:, :, 0] = contours2[i]['image'] / 255.0  # Red channel\n",
    "            overlay[:, :, 2] = contours1[i]['image'] / 255.0  # Blue channel\n",
    "            \n",
    "            axes[2, i].imshow(overlay)\n",
    "            sim = similarities[i]['structural_similarity']\n",
    "            axes[2, i].set_title(f'Overlay\\nSimilarity: {sim:.3f}')\n",
    "            axes[2, i].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def plot_similarity_metrics(self, similarities):\n",
    "        \"\"\"Plot similarity metrics over Y levels\"\"\"\n",
    "        if not similarities:\n",
    "            print(\"No similarity data to plot\")\n",
    "            return\n",
    "            \n",
    "        y_levels = [s['y_level'] for s in similarities]\n",
    "        structural_sim = [s['structural_similarity'] for s in similarities]\n",
    "        contour_matching = [s['contour_matching'] for s in similarities]\n",
    "        jaccard_sim = [s['jaccard_index'] for s in similarities]\n",
    "        hausdorff_sim = [s['hausdorff_distance'] for s in similarities]\n",
    "        \n",
    "        # Filter out any NaN values\n",
    "        valid_indices = []\n",
    "        for i in range(len(similarities)):\n",
    "            if (np.isfinite(structural_sim[i]) and np.isfinite(contour_matching[i]) and \n",
    "                np.isfinite(jaccard_sim[i]) and np.isfinite(hausdorff_sim[i])):\n",
    "                valid_indices.append(i)\n",
    "        \n",
    "        if not valid_indices:\n",
    "            print(\"No valid similarity data to plot\")\n",
    "            return\n",
    "        \n",
    "        # Filter data to valid indices\n",
    "        y_levels = [y_levels[i] for i in valid_indices]\n",
    "        structural_sim = [structural_sim[i] for i in valid_indices]\n",
    "        contour_matching = [contour_matching[i] for i in valid_indices]\n",
    "        jaccard_sim = [jaccard_sim[i] for i in valid_indices]\n",
    "        hausdorff_sim = [hausdorff_sim[i] for i in valid_indices]\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "        \n",
    "        axes[0, 0].plot(y_levels, structural_sim, 'b-o', linewidth=2)\n",
    "        axes[0, 0].set_title('Structural Similarity')\n",
    "        axes[0, 0].set_xlabel('Y Level')\n",
    "        axes[0, 0].set_ylabel('Similarity')\n",
    "        axes[0, 0].grid(True)\n",
    "        axes[0, 0].set_ylim([0, 1])\n",
    "        \n",
    "        axes[0, 1].plot(y_levels, contour_matching, 'g-s', linewidth=2)\n",
    "        axes[0, 1].set_title('Contour Feature Matching')\n",
    "        axes[0, 1].set_xlabel('Y Level')\n",
    "        axes[0, 1].set_ylabel('Similarity')\n",
    "        axes[0, 1].grid(True)\n",
    "        axes[0, 1].set_ylim([0, 1])\n",
    "        \n",
    "        axes[1, 0].plot(y_levels, jaccard_sim, 'r-^', linewidth=2)\n",
    "        axes[1, 0].set_title('Jaccard Index')\n",
    "        axes[1, 0].set_xlabel('Y Level')\n",
    "        axes[1, 0].set_ylabel('Similarity')\n",
    "        axes[1, 0].grid(True)\n",
    "        axes[1, 0].set_ylim([0, 1])\n",
    "        \n",
    "        axes[1, 1].plot(y_levels, hausdorff_sim, 'm-d', linewidth=2)\n",
    "        axes[1, 1].set_title('Hausdorff Distance Similarity')\n",
    "        axes[1, 1].set_xlabel('Y Level')\n",
    "        axes[1, 1].set_ylabel('Similarity')\n",
    "        axes[1, 1].grid(True)\n",
    "        axes[1, 1].set_ylim([0, 1])\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Overall similarity summary\n",
    "        overall_structural = np.mean(structural_sim) if structural_sim else 0.0\n",
    "        overall_contour = np.mean(contour_matching) if contour_matching else 0.0\n",
    "        overall_jaccard = np.mean(jaccard_sim) if jaccard_sim else 0.0\n",
    "        overall_hausdorff = np.mean(hausdorff_sim) if hausdorff_sim else 0.0\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"OVERALL SIMILARITY SUMMARY\")\n",
    "        print(\"=\"*50)\n",
    "        print(f\"Structural Similarity:     {overall_structural:.4f}\")\n",
    "        print(f\"Contour Feature Matching:  {overall_contour:.4f}\")\n",
    "        print(f\"Jaccard Index:             {overall_jaccard:.4f}\")\n",
    "        print(f\"Hausdorff Distance Sim:    {overall_hausdorff:.4f}\")\n",
    "        \n",
    "        valid_scores = [s for s in [overall_structural, overall_contour, overall_jaccard, overall_hausdorff] if s > 0]\n",
    "        if valid_scores:\n",
    "            print(f\"Average Overall Similarity: {np.mean(valid_scores):.4f}\")\n",
    "        else:\n",
    "            print(\"Average Overall Similarity: 0.0000\")\n",
    "        print(\"=\"*50)\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run the complete analysis\"\"\"\n",
    "    # File paths - modify these to point to your .obj files\n",
    "    obj_file1 = file1  # Replace with your first .obj file path\n",
    "    obj_file2 = file2  # Replace with your second .obj file path\n",
    "    \n",
    "    print(\"Loading OBJ files...\")\n",
    "    \n",
    "    # Check if files exist\n",
    "    if not os.path.exists(obj_file1):\n",
    "        print(f\"Error: File {obj_file1} not found!\")\n",
    "        print(\"Please place your first .obj file in the current directory and name it 'model1.obj'\")\n",
    "        return\n",
    "    \n",
    "    if not os.path.exists(obj_file2):\n",
    "        print(f\"Error: File {obj_file2} not found!\")\n",
    "        print(\"Please place your second .obj file in the current directory and name it 'model2.obj'\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        # Load OBJ files\n",
    "        obj1 = OBJLoader(obj_file1)\n",
    "        obj2 = OBJLoader(obj_file2)\n",
    "        \n",
    "        print(f\"Model 1: {len(obj1.vertices)} vertices, {len(obj1.faces)} faces\")\n",
    "        print(f\"Model 2: {len(obj2.vertices)} vertices, {len(obj2.faces)} faces\")\n",
    "        \n",
    "        # Create slicers\n",
    "        print(\"\\nGenerating Y-direction slices...\")\n",
    "        slicer1 = GeometryYSlicer(obj1, num_slices=15)\n",
    "        slicer2 = GeometryYSlicer(obj2, num_slices=15)\n",
    "        \n",
    "        # Extract contours\n",
    "        contours1 = slicer1.get_slice_contours()\n",
    "        contours2 = slicer2.get_slice_contours()\n",
    "        \n",
    "        print(f\"Generated {len(contours1)} slices for model 1\")\n",
    "        print(f\"Generated {len(contours2)} slices for model 2\")\n",
    "        \n",
    "        # Compare contours\n",
    "        print(\"\\nComparing contours...\")\n",
    "        comparator = ContourComparator()\n",
    "        similarities = comparator.compare_contours(contours1, contours2)\n",
    "        \n",
    "        # Visualize results\n",
    "        print(\"\\nGenerating visualizations...\")\n",
    "        visualizer = Visualizer()\n",
    "        \n",
    "        # Plot 3D models\n",
    "        visualizer.plot_3d_models(obj1, obj2)\n",
    "        \n",
    "        # Plot slice comparisons\n",
    "        visualizer.plot_slice_comparison(contours1, contours2, similarities)\n",
    "        \n",
    "        # Plot similarity metrics\n",
    "        visualizer.plot_similarity_metrics(similarities)\n",
    "        \n",
    "        print(\"\\nAnalysis complete!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during analysis: {str(e)}\")\n",
    "        print(\"Please check that your .obj files are valid and properly formatted.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
